{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from shrimp.src.validation.model_validation_suite import RegressorValidationSuite, ClassifierValidationSuite\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# error metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(10000)\n",
    "y = np.where(y == 0, -1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment X with intercept\n",
    "X = np.concatenate((np.ones(10000)[:,np.newaxis], X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 21)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X, axis=1)\n",
    "# X = X / np.abs(X.max(axis = 0))\n",
    "# X /= np.sqrt(21)\n",
    "assert (np.linalg.norm(X, axis=1) <= 1.00000001).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression via SGD\n",
    "clf = SGDClassifier(loss='log', penalty='l2', l1_ratio=0, alpha=1.5, verbose=True, fit_intercept=False,\n",
    "                    learning_rate='bolton', eta0=0.4, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.21, NNZs: 21, Bias: 0.000000, T: 10000, Avg. loss: 0.681942, learning_rate: 0.4000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 21, Bias: 0.000000, T: 20000, Avg. loss: 0.681753, learning_rate: 0.4000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.20, NNZs: 21, Bias: 0.000000, T: 30000, Avg. loss: 0.681990, learning_rate: 0.3333\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 21, Bias: 0.000000, T: 40000, Avg. loss: 0.681543, learning_rate: 0.2222\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.17, NNZs: 21, Bias: 0.000000, T: 50000, Avg. loss: 0.681651, learning_rate: 0.1667\n",
      "Total training time: 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrei/Documents/scikit-learn/sklearn/linear_model/stochastic_gradient.py:131: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \" default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1.5, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.4, fit_intercept=False, l1_ratio=0, learning_rate='bolton',\n",
       "       loss='log', max_iter=None, n_iter=None, n_jobs=1, penalty='l2',\n",
       "       power_t=0.5, random_state=2017, shuffle=True, tol=None,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y, R=2/3, beta=2.5, gamma=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83764225878032894"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, clf.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75360000000000005"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3515, 1470],\n",
       "       [ 994, 4021]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, clf.predict(X), labels = [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04874059, -0.03453356, -0.00367876, -0.04793597,  0.07130633,\n",
       "         0.01213033,  0.00648209,  0.01978853, -0.01433956, -0.02793671,\n",
       "        -0.05231319,  0.03778253,  0.01704509, -0.03298822, -0.00594396,\n",
       "         0.03933785,  0.01110224,  0.0442674 , -0.0104631 ,  0.04087745,\n",
       "        -0.01632564]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOLT-ON Logistic DP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### constant learning rate with strongly-convex loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.bolt_on(epsilon = 1, m = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04846948, -0.03202115, -0.00485479, -0.04903067,  0.07065142,\n",
       "         0.01151456,  0.00596402,  0.01935841, -0.01292029, -0.02918155,\n",
       "        -0.05266361,  0.03735564,  0.017023  , -0.03271994, -0.00625434,\n",
       "         0.03989092,  0.01301727,  0.04521685, -0.01138789,  0.04072074,\n",
       "        -0.01767802]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82880278008104069"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, clf.predict_proba(X_unit)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73640000000000005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, clf.predict(X_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3128, 1893],\n",
       "       [ 743, 4236]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, clf.predict(X_unit), labels = [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import gauss\n",
    "\n",
    "# def make_rand_vector(dims):\n",
    "#     vec = np.array([gauss(0, 1) for i in range(dims)])\n",
    "#     return vec / np.linalg.norm(vec)\n",
    "\n",
    "# # Parameters for Laplacian noise\n",
    "# alpha = 1.5\n",
    "# L = 2\n",
    "# beta = 1 + alpha\n",
    "# gamma = alpha\n",
    "# eta = 0.4\n",
    "\n",
    "# # num features + intercept\n",
    "# d= 21\n",
    "\n",
    "# # L2 sensitivity of the learning algorithm\n",
    "# L2_sensitivity = (2*eta*L)/(1 - (1-eta*gamma)**X_unit.shape[0])\n",
    "\n",
    "# # sampling from the associated Laplace distribution\n",
    "# epsilon = 2\n",
    "# v = make_rand_vector(d)\n",
    "# magnitude = np.random.gamma(d, L2_sensitivity/epsilon)\n",
    "# noise = v*magnitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
